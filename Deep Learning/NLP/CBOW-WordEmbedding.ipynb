{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\",\n",
    "#                                   \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "#                                   True,\n",
    "#                                   cache_dir= '.',\n",
    "#                                  cache_subdir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = os.path.dirname(\"aclImdb_v1.tar.gz\")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb\n"
     ]
    }
   ],
   "source": [
    "dataset_dir  = os.path.join(path, \"aclImdb\")\n",
    "print(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_dir, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb\\train\n"
     ]
    }
   ],
   "source": [
    "print(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeledBow.feat',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'unsupBow.feat',\n",
       " 'urls_neg.txt',\n",
       " 'urls_pos.txt',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_dir = os.path.join( train_dir, \"unsup\") this step is already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(remove_dir)  this step is already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.text_dataset_from_directory(train_dir, batch_size = batch_size, validation_split=0.2 , subset=\"training\", seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(train_dir, batch_size = batch_size, validation_split = 0.2 , subset=\"validation\", seed= seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 b'This film\\'s trailer interested me enough to warrant renting the DVD. However, the resulting movie is absolutely dire! Admittedly, this is not the worst film ever made, or the worst film this year, but it came damn close!<br /><br />The main issue is the film not knowing what it wants to be: comedy, adult drama, thriller, teen-porn? The story is interesting, as it deals with the pitfalls of mail-order brides, but the film is a mess. What starts out as a mildly interesting \"comedy\" (a word I use in the loosest possible terms), then goes totally in reverse, and degenerates into a very dark and distasteful misogynistic thriller. Nicole Kidman should know better, and Ben Chaplin is wasted! As are Matthieu Kassovitz and Vincent Cassel, whom I can only presume did this for the money.<br /><br />This is a bad film in pretty much every single aspect. It\\'s not funny, it\\'s almost so sexist that you could almost forgive Benny Hill for everything he did, and the dramatic elements are just downright nasty. A film to be avoided, unless you absolutely have to see Kidman or Chaplin in every one of their films!'\n",
      "0 b'This movie should have never been made.<br /><br />What a shame of the budget.<br /><br />Please hire convincing actors, and make a proper movie. Very thin plot, and unconvincing lines. Almost hilarious, and that is a shame for an action movie.... <br /><br />Definitely not worth watching.<br /><br />They keep replaying the same \"shots\" of an Stealth airplane flying away. You have seen it ones, and that was not worth re-running 3 or 4 times.<br /><br />It is time for Steven Seagal to retire from movie-making.<br /><br />His movies are getting worser every time.<br /><br />Black Dawn, and Submerged were already bad, but this movie is even worse.'\n",
      "0 b'Just saw it yesterday in the Sao Paulo Intl Film Festival. Just before going I came here to see how it was rated, and at that time it was 7.4, a pretty nice rate...<br /><br />After 15 minutes I was dying to get out (never did this), but felt embarrassed to do so as the producer of the movie was in the screening.<br /><br />I did not like at all, the dialogs are shallow and lead nowhere, the characters are shallower than the dialogs, nothing lead anywhere, and the worst and worst: plenty of Siemens and Organics advertising on the movie. Despite the fact that I already paid to go to the movie and entertain myself, I still have to be bombarded by the main character chatting on the internet and Siemens mobile popping-up all the time on her lap-top; or another character having a bath or cutting her hair just to have Organics shampoo displayed enormously on the screen! All of this would be bearable if the plot, characters, romances, anything was good, but was bad, really bad! A \"don\\'t know how to do\" sex-in-the-city.<br /><br />Don\\'t waste your time or money.'\n",
      "1 b\"This movie is incredibly realistic and I feel does a great justice to the crime that many people do not understand because of a lack of experience. The many people who think they could fathom what goes through a victim's mind are arrogant. As a victim, I feel that Dawson did a fantastic job in her role of Maya. I agree that this is an incredibly brave film. This looks at rape from a different, more realistic standpoint than any other movie I've ever seen on the subject. The end did drag on a bit long, but I know that many victims imagine this kind of justice, since the chances of an attacker being sent to jail for their crime is around 1%. It's good to see a movie that sticks closer to reality than most would dare to.\"\n",
      "1 b'I attended Camp Chesapeake. It was located at the head of the Chesapeake bay on the North East River in MD. It was a similar type summer camp with cabins. It was established by the Coatesville, PA YMCA. I started out as a young camper and later became a Junior, Senior counselor and later, the Waterfront director. If the camp had continued, I would have done anything within my power to become the camp director. Alas the powers of the YMCA decided to close down the camp and sell it to the state of MD. I visited the former camp some years later by boat and was dismayed by the neglect of the state of MD and natural destruction by mother nature. The 350 acre site served so many with all the benefits of contact with natures offerings. A black man by the name of Curtis Ford, and his family were residents and caretakers of the property. Mr Curtis was my friend and mentor. I idolized his every being. Even as he could not swim he was a waterman. If I asked him where the fish were biting, he would designate the spot, and I would have a ball. Ther was also a Family camp at the end of the summer. These memories will be with me for eternity.'\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    for i in range(5):\n",
    "        print(label_batch[i].numpy(), text_batch[i].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds   = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = embedding_layer(tf.constant([3, 7, 9, 10, 11, 200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 5), dtype=float32, numpy=\n",
       "array([[ 0.02511052,  0.01828988, -0.01169553, -0.00181482,  0.02978926],\n",
       "       [-0.00285812,  0.00912962,  0.04531452, -0.0196569 , -0.02837334],\n",
       "       [ 0.02840414,  0.01021618, -0.04309234,  0.00395962, -0.03067114],\n",
       "       [ 0.00883833,  0.03317884, -0.03403064,  0.02822263,  0.01268062],\n",
       "       [-0.0349094 ,  0.03444279,  0.03563032,  0.04942328,  0.04480261],\n",
       "       [-0.02943516, -0.01693821,  0.00580652, -0.02758094,  0.0145897 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_layer.get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = embedding_layer(tf.constant([[0,1,2,3],[3,4,5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 5), dtype=float32, numpy=\n",
       "array([[[ 0.0355163 ,  0.04144997, -0.03554094,  0.02133859,\n",
       "          0.02183565],\n",
       "        [-0.01927599, -0.00717426,  0.04862859, -0.02970214,\n",
       "          0.04600758],\n",
       "        [ 0.00317008, -0.00040751,  0.01963696,  0.02729354,\n",
       "          0.00213166],\n",
       "        [ 0.02511052,  0.01828988, -0.01169553, -0.00181482,\n",
       "          0.02978926]],\n",
       "\n",
       "       [[ 0.02511052,  0.01828988, -0.01169553, -0.00181482,\n",
       "          0.02978926],\n",
       "        [ 0.0402602 ,  0.04003313,  0.02967794, -0.04804343,\n",
       "          0.0483623 ],\n",
       "        [ 0.04866591, -0.01627334, -0.01257658,  0.01128574,\n",
       "         -0.0135993 ],\n",
       "        [-0.04244554, -0.03557456, -0.03991872, -0.02145844,\n",
       "         -0.00908531]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br/', ' ')\n",
    "    final_data = tf.strings.regex_replace(stripped_html, re.escape(string.punctuation), '')\n",
    "    print(final_data)\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "sequence_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    standardize = custom_standardization,\n",
    "    max_tokens  = vocab_size,\n",
    "    output_mode = 'int', \n",
    "    output_sequence_length = sequence_length\n",
    ")\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "text_ds = train_ds.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"StaticRegexReplace_1:0\", shape=(None, 1), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "adapt = vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'the',\n",
       " 'a',\n",
       " 'and',\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'in',\n",
       " 'i',\n",
       " 'this',\n",
       " 'that',\n",
       " 'it',\n",
       " '/><br',\n",
       " 'was',\n",
       " 'as',\n",
       " 'for',\n",
       " 'with',\n",
       " 'but',\n",
       " 'on',\n",
       " 'movie',\n",
       " 'his',\n",
       " 'are',\n",
       " 'not',\n",
       " 'film',\n",
       " 'you',\n",
       " 'have',\n",
       " 'he',\n",
       " 'be',\n",
       " 'at',\n",
       " 'one',\n",
       " 'by',\n",
       " 'an',\n",
       " 'they',\n",
       " 'from',\n",
       " 'all',\n",
       " 'who',\n",
       " 'like',\n",
       " 'so',\n",
       " 'just',\n",
       " 'or',\n",
       " 'has',\n",
       " 'about',\n",
       " 'her',\n",
       " \"it's\",\n",
       " 'some',\n",
       " 'if',\n",
       " 'out',\n",
       " 'what',\n",
       " 'very',\n",
       " 'when',\n",
       " 'more',\n",
       " 'there',\n",
       " 'she',\n",
       " 'would',\n",
       " 'good',\n",
       " 'even',\n",
       " 'my',\n",
       " 'only',\n",
       " 'no',\n",
       " 'their',\n",
       " 'had',\n",
       " 'really',\n",
       " 'which',\n",
       " 'can',\n",
       " 'up',\n",
       " 'were',\n",
       " 'see',\n",
       " 'than',\n",
       " '-',\n",
       " 'we',\n",
       " 'been',\n",
       " 'get',\n",
       " 'will',\n",
       " 'into',\n",
       " 'story',\n",
       " 'because',\n",
       " 'much',\n",
       " 'most',\n",
       " 'how',\n",
       " 'other',\n",
       " 'also',\n",
       " 'its',\n",
       " \"don't\",\n",
       " 'time',\n",
       " 'do',\n",
       " 'first',\n",
       " 'great',\n",
       " 'people',\n",
       " 'me',\n",
       " 'could',\n",
       " 'make',\n",
       " 'any',\n",
       " '/>the',\n",
       " 'after',\n",
       " 'made',\n",
       " 'then',\n",
       " 'bad',\n",
       " 'think',\n",
       " 'him',\n",
       " 'many',\n",
       " 'never',\n",
       " 'being',\n",
       " 'two',\n",
       " 'too',\n",
       " 'where',\n",
       " 'little',\n",
       " 'well',\n",
       " '<br',\n",
       " 'way',\n",
       " 'watch',\n",
       " 'your',\n",
       " 'it.',\n",
       " 'did',\n",
       " 'does',\n",
       " 'them',\n",
       " 'know',\n",
       " 'best',\n",
       " 'love',\n",
       " 'characters',\n",
       " 'seen',\n",
       " 'movie.',\n",
       " 'these',\n",
       " 'character',\n",
       " 'movies',\n",
       " 'ever',\n",
       " 'still',\n",
       " 'over',\n",
       " 'films',\n",
       " 'plot',\n",
       " 'should',\n",
       " 'such',\n",
       " 'while',\n",
       " 'acting',\n",
       " 'show',\n",
       " 'go',\n",
       " 'better',\n",
       " 'those',\n",
       " 'film.',\n",
       " 'through',\n",
       " 'off',\n",
       " \"doesn't\",\n",
       " 'say',\n",
       " 'why',\n",
       " 'something',\n",
       " \"i'm\",\n",
       " 'makes',\n",
       " \"didn't\",\n",
       " 'back',\n",
       " 'watching',\n",
       " 'scene',\n",
       " 'film,',\n",
       " 'real',\n",
       " 'few',\n",
       " 'movie,',\n",
       " 'find',\n",
       " 'actually',\n",
       " 'new',\n",
       " 'scenes',\n",
       " 'man',\n",
       " 'every',\n",
       " 'life',\n",
       " 'going',\n",
       " '/>i',\n",
       " 'nothing',\n",
       " 'same',\n",
       " 'look',\n",
       " 'quite',\n",
       " 'another',\n",
       " 'old',\n",
       " 'lot',\n",
       " 'end',\n",
       " 'got',\n",
       " 'pretty',\n",
       " 'want',\n",
       " 'thing',\n",
       " 'seems',\n",
       " 'before',\n",
       " '&',\n",
       " \"can't\",\n",
       " 'take',\n",
       " 'years',\n",
       " 'part',\n",
       " 'give',\n",
       " 'actors',\n",
       " 'young',\n",
       " 'may',\n",
       " 'between',\n",
       " \"that's\",\n",
       " \"i've\",\n",
       " 'us',\n",
       " 'though',\n",
       " 'gets',\n",
       " 'without',\n",
       " 'both',\n",
       " 'here',\n",
       " 'things',\n",
       " 'saw',\n",
       " 'thought',\n",
       " 'big',\n",
       " 'always',\n",
       " 'around',\n",
       " \"isn't\",\n",
       " 'now',\n",
       " 'must',\n",
       " 'it,',\n",
       " 'director',\n",
       " 'almost',\n",
       " 'own',\n",
       " 'come',\n",
       " 'work',\n",
       " 'horror',\n",
       " 'cast',\n",
       " 'down',\n",
       " 'whole',\n",
       " 'might',\n",
       " \"there's\",\n",
       " \"he's\",\n",
       " 'probably',\n",
       " 'bit',\n",
       " 'least',\n",
       " 'enough',\n",
       " 'am',\n",
       " 'last',\n",
       " 'feel',\n",
       " '\"the',\n",
       " 'since',\n",
       " 'original',\n",
       " 'far',\n",
       " 'rather',\n",
       " 'long',\n",
       " 'fact',\n",
       " 'kind',\n",
       " 'each',\n",
       " 'world',\n",
       " 'found',\n",
       " 'funny',\n",
       " 'anything',\n",
       " 'comes',\n",
       " 'worst',\n",
       " 'making',\n",
       " 'having',\n",
       " 'trying',\n",
       " 'however,',\n",
       " 'right',\n",
       " 'action',\n",
       " 'done',\n",
       " 'interesting',\n",
       " 'our',\n",
       " 'point',\n",
       " 'believe',\n",
       " 'looks',\n",
       " 'guy',\n",
       " 'put',\n",
       " 'family',\n",
       " 'goes',\n",
       " '/>this',\n",
       " 'played',\n",
       " 'hard',\n",
       " 'series',\n",
       " 'anyone',\n",
       " 'main',\n",
       " \"wasn't\",\n",
       " 'performance',\n",
       " 'especially',\n",
       " 'role',\n",
       " 'music',\n",
       " 'yet',\n",
       " 'seem',\n",
       " 'someone',\n",
       " 'plays',\n",
       " 'watched',\n",
       " 'worth',\n",
       " 'takes',\n",
       " 'sure',\n",
       " 'script',\n",
       " 'looking',\n",
       " 'minutes',\n",
       " 'during',\n",
       " 'tv',\n",
       " 'three',\n",
       " 'maybe',\n",
       " 'different',\n",
       " 'although',\n",
       " 'set',\n",
       " 'shows',\n",
       " 'times',\n",
       " 'woman',\n",
       " 'away',\n",
       " 'girl',\n",
       " 'comedy',\n",
       " 'time.',\n",
       " 'john',\n",
       " 'left',\n",
       " 'once',\n",
       " 'everything',\n",
       " \"you're\",\n",
       " 'seeing',\n",
       " 'simply',\n",
       " 'fun',\n",
       " 'special',\n",
       " 'american',\n",
       " 'everyone',\n",
       " 'completely',\n",
       " 'read',\n",
       " 'true',\n",
       " 'play',\n",
       " 'well,',\n",
       " 'reason',\n",
       " 'until',\n",
       " 'need',\n",
       " 'again',\n",
       " 'nice',\n",
       " 'given',\n",
       " 'used',\n",
       " 'use',\n",
       " 'high',\n",
       " 'beautiful',\n",
       " 'sense',\n",
       " 'idea',\n",
       " 'version',\n",
       " 'rest',\n",
       " 'help',\n",
       " 'place',\n",
       " 'truly',\n",
       " 'dvd',\n",
       " 'less',\n",
       " '--',\n",
       " 'try',\n",
       " 'job',\n",
       " 'recommend',\n",
       " 'black',\n",
       " 'money',\n",
       " 'came',\n",
       " 'getting',\n",
       " 'excellent',\n",
       " 'second',\n",
       " 'instead',\n",
       " 'actor',\n",
       " '(and',\n",
       " 'full',\n",
       " 'ending',\n",
       " 'poor',\n",
       " 'keep',\n",
       " 'gives',\n",
       " 'tell',\n",
       " 'couple',\n",
       " 'let',\n",
       " 'shot',\n",
       " 'himself',\n",
       " 'definitely',\n",
       " 'playing',\n",
       " 'half',\n",
       " 'become',\n",
       " 'said',\n",
       " 'day',\n",
       " 'enjoy',\n",
       " 'felt',\n",
       " 'supposed',\n",
       " 'audience',\n",
       " 'understand',\n",
       " 'star',\n",
       " 'effects',\n",
       " 'fan',\n",
       " 'early',\n",
       " 'all,',\n",
       " 'small',\n",
       " 'liked',\n",
       " 'together',\n",
       " 'book',\n",
       " 'remember',\n",
       " 'absolutely',\n",
       " 'against',\n",
       " 'along',\n",
       " \"couldn't\",\n",
       " 'entire',\n",
       " 'waste',\n",
       " 'went',\n",
       " 'doing',\n",
       " 'later',\n",
       " 'next',\n",
       " 'hollywood',\n",
       " 'year',\n",
       " 'start',\n",
       " 'human',\n",
       " 'often',\n",
       " 'perhaps',\n",
       " 'wife',\n",
       " 'screen',\n",
       " 'several',\n",
       " 'certainly',\n",
       " 'wonderful',\n",
       " 'time,',\n",
       " '2',\n",
       " 'is,',\n",
       " 'men',\n",
       " 'loved',\n",
       " 'sort',\n",
       " 'short',\n",
       " 'night',\n",
       " 'kids',\n",
       " '(the',\n",
       " 'becomes',\n",
       " 'war',\n",
       " 'classic',\n",
       " '10',\n",
       " \"she's\",\n",
       " 'production',\n",
       " 'wanted',\n",
       " 'father',\n",
       " 'house',\n",
       " 'seemed',\n",
       " 'home',\n",
       " 'live',\n",
       " 'else',\n",
       " '\\x96',\n",
       " 'hope',\n",
       " 'top',\n",
       " 'camera',\n",
       " 'piece',\n",
       " 'women',\n",
       " '.',\n",
       " 'that,',\n",
       " 'tries',\n",
       " 'lost',\n",
       " \"i'd\",\n",
       " 'totally',\n",
       " 'video',\n",
       " 'them.',\n",
       " 'final',\n",
       " 'called',\n",
       " \"you'll\",\n",
       " 'based',\n",
       " 'mind',\n",
       " 'line',\n",
       " 'wants',\n",
       " 'under',\n",
       " 'course',\n",
       " 'performances',\n",
       " 'death',\n",
       " 'gave',\n",
       " 'already',\n",
       " \"they're\",\n",
       " 'friends',\n",
       " 'able',\n",
       " 'perfect',\n",
       " 'enjoyed',\n",
       " 'story,',\n",
       " 'either',\n",
       " 'finally',\n",
       " 'problem',\n",
       " 'turns',\n",
       " 'name',\n",
       " 'person',\n",
       " 'episode',\n",
       " 'stupid',\n",
       " 'care',\n",
       " \"won't\",\n",
       " 'one.',\n",
       " 'despite',\n",
       " 'him.',\n",
       " 'turn',\n",
       " 'favorite',\n",
       " 'behind',\n",
       " 'starts',\n",
       " 'low',\n",
       " 'face',\n",
       " 'this,',\n",
       " 'school',\n",
       " 'dead',\n",
       " 'sex',\n",
       " 'and,',\n",
       " 'this.',\n",
       " 'lead',\n",
       " 'moments',\n",
       " 'me.',\n",
       " 'white',\n",
       " 'mean',\n",
       " 'written',\n",
       " 'stars',\n",
       " 'guess',\n",
       " 'michael',\n",
       " 'fine',\n",
       " 'me,',\n",
       " 'head',\n",
       " 'sound',\n",
       " 'lines',\n",
       " 'title',\n",
       " 'cannot',\n",
       " 'story.',\n",
       " 'kill',\n",
       " 'budget',\n",
       " 'took',\n",
       " \"film's\",\n",
       " 'well.',\n",
       " 'good.',\n",
       " 'highly',\n",
       " 'lack',\n",
       " 'extremely',\n",
       " 'terrible',\n",
       " 'heard',\n",
       " 'throughout',\n",
       " 'others',\n",
       " 'dialogue',\n",
       " 'sometimes',\n",
       " 'evil',\n",
       " 'style',\n",
       " 'all.',\n",
       " 'itself',\n",
       " 'killer',\n",
       " 'fans',\n",
       " 'boring',\n",
       " 'case',\n",
       " 'fight',\n",
       " 'beginning',\n",
       " \"wouldn't\",\n",
       " 'feeling',\n",
       " 'dark',\n",
       " 'lives',\n",
       " 'life.',\n",
       " 'obviously',\n",
       " 'complete',\n",
       " 'soon',\n",
       " 'good,',\n",
       " 'particularly',\n",
       " 'decent',\n",
       " 'boy',\n",
       " 'works',\n",
       " 'friend',\n",
       " 'course,',\n",
       " 'late',\n",
       " '/>it',\n",
       " 'mr.',\n",
       " 'looked',\n",
       " 'close',\n",
       " 'expect',\n",
       " '/>in',\n",
       " 'directed',\n",
       " 'mother',\n",
       " 'thinking',\n",
       " 'picture',\n",
       " 'leave',\n",
       " 'wrong',\n",
       " 'finds',\n",
       " 'quality',\n",
       " 'guys',\n",
       " 'attempt',\n",
       " 'whose',\n",
       " 'amazing',\n",
       " '!',\n",
       " 'entertaining',\n",
       " 'wonder',\n",
       " 'viewer',\n",
       " 'save',\n",
       " 'exactly',\n",
       " 'taken',\n",
       " 'somewhat',\n",
       " 'run',\n",
       " 'writing',\n",
       " 'police',\n",
       " 'movies.',\n",
       " 'across',\n",
       " 'worse',\n",
       " 'huge',\n",
       " 'obvious',\n",
       " 'living',\n",
       " '3',\n",
       " 'strong',\n",
       " 'direction',\n",
       " 'says',\n",
       " 'usually',\n",
       " 'except',\n",
       " 'awful',\n",
       " '/>if',\n",
       " 'past',\n",
       " 'number',\n",
       " 'parts',\n",
       " 'films,',\n",
       " 'type',\n",
       " 'opening',\n",
       " 'group',\n",
       " 'james',\n",
       " 'girls',\n",
       " 'wish',\n",
       " 'running',\n",
       " 'coming',\n",
       " 'movies,',\n",
       " 'supporting',\n",
       " 'shown',\n",
       " 'side',\n",
       " 'tells',\n",
       " 'car',\n",
       " 'bad.',\n",
       " 'laugh',\n",
       " 'acting,',\n",
       " 'local',\n",
       " 'started',\n",
       " 'told',\n",
       " 'stop',\n",
       " 'myself',\n",
       " 'turned',\n",
       " 'none',\n",
       " 'game',\n",
       " 'major',\n",
       " 'taking',\n",
       " 'hour',\n",
       " 'female',\n",
       " 'killed',\n",
       " 'again,',\n",
       " 'known',\n",
       " 'that.',\n",
       " 'here,',\n",
       " 'children',\n",
       " 'musical',\n",
       " 'voice',\n",
       " \"i'll\",\n",
       " 'fact,',\n",
       " 'act',\n",
       " 'call',\n",
       " 'british',\n",
       " 'david',\n",
       " 'town',\n",
       " 'due',\n",
       " 'it.<br',\n",
       " 'son',\n",
       " 'falls',\n",
       " ',',\n",
       " 'bring',\n",
       " 'talking',\n",
       " 'including',\n",
       " \"aren't\",\n",
       " 'heart',\n",
       " 'single',\n",
       " 'knew',\n",
       " 'here.',\n",
       " 'clearly',\n",
       " 'way,',\n",
       " 'order',\n",
       " 'history',\n",
       " 'mostly',\n",
       " 'brilliant',\n",
       " 'giving',\n",
       " 'stories',\n",
       " 'robert',\n",
       " 'happens',\n",
       " 'actress',\n",
       " 'out.',\n",
       " 'modern',\n",
       " 'characters,',\n",
       " 'involved',\n",
       " 'saying',\n",
       " 'humor',\n",
       " 'end,',\n",
       " 'drama',\n",
       " 'hit',\n",
       " 'cinema',\n",
       " 'whether',\n",
       " 'horrible',\n",
       " 'ends',\n",
       " '/>there',\n",
       " 'eyes',\n",
       " 'bad,',\n",
       " 'easily',\n",
       " 'one,',\n",
       " 'yes,',\n",
       " 'knows',\n",
       " 'chance',\n",
       " 'matter',\n",
       " 'example',\n",
       " 'nearly',\n",
       " 'child',\n",
       " 'again.',\n",
       " 'themselves',\n",
       " \"haven't\",\n",
       " 'art',\n",
       " 'kid',\n",
       " 'however',\n",
       " 'actual',\n",
       " 'needs',\n",
       " 'four',\n",
       " 'feels',\n",
       " 'cut',\n",
       " 'serious',\n",
       " 'moment',\n",
       " 'is.',\n",
       " 'change',\n",
       " 'released',\n",
       " 'usual',\n",
       " 'five',\n",
       " 'beyond',\n",
       " 'similar',\n",
       " 'end.',\n",
       " 'using',\n",
       " 'upon',\n",
       " 'mention',\n",
       " 'slow',\n",
       " 'english',\n",
       " 'simple',\n",
       " 'seen.',\n",
       " 'appears',\n",
       " 'important',\n",
       " '/>but',\n",
       " '/>',\n",
       " '/>and',\n",
       " 'happened',\n",
       " 'films.',\n",
       " 'plot,',\n",
       " 'within',\n",
       " 'strange',\n",
       " 'relationship',\n",
       " 'lots',\n",
       " 'george',\n",
       " 'song',\n",
       " 'but,',\n",
       " 'way.',\n",
       " 'named',\n",
       " 'bunch',\n",
       " 'murder',\n",
       " 'kept',\n",
       " 'city',\n",
       " 'apparently',\n",
       " '(i',\n",
       " 'hours',\n",
       " 'him,',\n",
       " 'among',\n",
       " 'body',\n",
       " 'miss',\n",
       " 'cheap',\n",
       " 'stuff',\n",
       " 'brought',\n",
       " 'days',\n",
       " 'comic',\n",
       " '/>a',\n",
       " 'overall',\n",
       " 'fall',\n",
       " 'blood',\n",
       " 'near',\n",
       " 'certain',\n",
       " 'middle',\n",
       " 'basically',\n",
       " 'yourself',\n",
       " 'her.',\n",
       " 'interest',\n",
       " 'happy',\n",
       " '/>as',\n",
       " 'sad',\n",
       " 'stay',\n",
       " 'life,',\n",
       " 'film.<br',\n",
       " 'score',\n",
       " 'movie.<br',\n",
       " 'view',\n",
       " 'romantic',\n",
       " 'talk',\n",
       " 'songs',\n",
       " 'so,',\n",
       " 'greatest',\n",
       " 'begins',\n",
       " 'tried',\n",
       " 'famous',\n",
       " 'showing',\n",
       " 'events',\n",
       " 'typical',\n",
       " 'buy',\n",
       " 'add',\n",
       " 'working',\n",
       " 'hear',\n",
       " 'age',\n",
       " 'paul',\n",
       " 'decided',\n",
       " 'de',\n",
       " 'hate',\n",
       " 'documentary',\n",
       " '(as',\n",
       " \"you've\",\n",
       " 'surprised',\n",
       " '(which',\n",
       " 'shots',\n",
       " 'became',\n",
       " 'alone',\n",
       " 'french',\n",
       " \"what's\",\n",
       " 'sit',\n",
       " 'brother',\n",
       " 'please',\n",
       " 'on.',\n",
       " 'jack',\n",
       " 'above',\n",
       " 'learn',\n",
       " 'annoying',\n",
       " 'sets',\n",
       " 'easy',\n",
       " 'too.',\n",
       " 'gore',\n",
       " 'violence',\n",
       " 'hell',\n",
       " 'experience',\n",
       " '1',\n",
       " 'peter',\n",
       " 'stand',\n",
       " 'cinematography',\n",
       " 'king',\n",
       " 'possibly',\n",
       " 'power',\n",
       " 'jokes',\n",
       " 'daughter',\n",
       " 'meets',\n",
       " 'japanese',\n",
       " \"who's\",\n",
       " 'red',\n",
       " 'ones',\n",
       " 'light',\n",
       " 'happen',\n",
       " \"/>it's\",\n",
       " 'funny,',\n",
       " 'funny.',\n",
       " 'flick',\n",
       " 'straight',\n",
       " 'hand',\n",
       " 'cool',\n",
       " 'attention',\n",
       " 'reading',\n",
       " 'oh',\n",
       " 'means',\n",
       " 'elements',\n",
       " 'richard',\n",
       " 'nor',\n",
       " 'characters.',\n",
       " 'ten',\n",
       " 'also,',\n",
       " 'sequence',\n",
       " 'realize',\n",
       " 'lady',\n",
       " 'word',\n",
       " 'television',\n",
       " 'incredibly',\n",
       " 'brings',\n",
       " 'sexual',\n",
       " 'possible',\n",
       " 'god',\n",
       " 'review',\n",
       " 'difficult',\n",
       " 'say,',\n",
       " 'poorly',\n",
       " 'silly',\n",
       " 'on,',\n",
       " 'unfortunately',\n",
       " 'oscar',\n",
       " 'leads',\n",
       " 'genre',\n",
       " 'emotional',\n",
       " 'clear',\n",
       " 'character,',\n",
       " 'imagine',\n",
       " 'episodes',\n",
       " 'scary',\n",
       " 'rent',\n",
       " 'killing',\n",
       " 'husband',\n",
       " '5',\n",
       " 'keeps',\n",
       " 'room',\n",
       " 'them,',\n",
       " 'roles',\n",
       " 'tom',\n",
       " 'out,',\n",
       " 'leaves',\n",
       " 'deal',\n",
       " 'third',\n",
       " 'moving',\n",
       " 'eventually',\n",
       " 'towards',\n",
       " 'message',\n",
       " 'figure',\n",
       " 'animation',\n",
       " '(or',\n",
       " 'show.',\n",
       " 'needed',\n",
       " 'enjoyable',\n",
       " 'comments',\n",
       " 'write',\n",
       " 'theme',\n",
       " 'leading',\n",
       " 'though,',\n",
       " 'forget',\n",
       " 'problems',\n",
       " 'previous',\n",
       " 'reality',\n",
       " 'rock',\n",
       " 'novel',\n",
       " 'career',\n",
       " 'various',\n",
       " 'move',\n",
       " 'level',\n",
       " 'doubt',\n",
       " 'better.',\n",
       " 'somehow',\n",
       " 'meant',\n",
       " 'there.',\n",
       " 'filmed',\n",
       " 'fast',\n",
       " 'talent',\n",
       " 'personal',\n",
       " 'fairly',\n",
       " 'writer',\n",
       " 'gone',\n",
       " 'whom',\n",
       " 'plenty',\n",
       " 'manages',\n",
       " 'hero',\n",
       " 'country',\n",
       " 'check',\n",
       " 'total',\n",
       " 'ridiculous',\n",
       " 'reviews',\n",
       " 'meet',\n",
       " 'hardly',\n",
       " 'herself',\n",
       " 'create',\n",
       " 'feature',\n",
       " 'unless',\n",
       " 'you.',\n",
       " 'words',\n",
       " 'theater',\n",
       " 'future',\n",
       " 'work.',\n",
       " 'hilarious',\n",
       " 'attempts',\n",
       " '(a',\n",
       " 'now,',\n",
       " 'up.',\n",
       " 'interested',\n",
       " 'forced',\n",
       " 'fantastic',\n",
       " 'effort',\n",
       " 'begin',\n",
       " 'tale',\n",
       " 'watch.',\n",
       " 'sounds',\n",
       " 'older',\n",
       " 'follow',\n",
       " 'scene,',\n",
       " 'average',\n",
       " '4',\n",
       " 'whatever',\n",
       " 'weak',\n",
       " 'avoid',\n",
       " 'scenes,',\n",
       " 'mystery',\n",
       " 'unfortunately,',\n",
       " 'points',\n",
       " 'features',\n",
       " 'political',\n",
       " 'form',\n",
       " 'dramatic',\n",
       " 'particular',\n",
       " 'expecting',\n",
       " 'lee',\n",
       " 'team',\n",
       " 'premise',\n",
       " 'york',\n",
       " 'subject',\n",
       " 'disney',\n",
       " 'dance',\n",
       " 'up,',\n",
       " 'male',\n",
       " 'uses',\n",
       " 'then,',\n",
       " 'forward',\n",
       " 'ask',\n",
       " 'zombie',\n",
       " 'worked',\n",
       " 'plain',\n",
       " 'man,',\n",
       " 'decides',\n",
       " 'her,',\n",
       " 'fails',\n",
       " 'there,',\n",
       " 'crap',\n",
       " 'appear',\n",
       " 'front',\n",
       " 'pay',\n",
       " 'dialog',\n",
       " 'badly',\n",
       " 'minute',\n",
       " 'expected',\n",
       " 'portrayed',\n",
       " 'general',\n",
       " 'crime',\n",
       " 'wait',\n",
       " 'predictable',\n",
       " 'viewers',\n",
       " 'open',\n",
       " 'joe',\n",
       " 'deep',\n",
       " 'slightly',\n",
       " 'compared',\n",
       " 'comment',\n",
       " 'social',\n",
       " 'sees',\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"text_vectorization/StaticRegexReplace_1:0\", shape=(None, 1), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "# Start by creating an explicit input layer. It needs to have a shape of\n",
    "# (1,) (because we need to guarantee that there is exactly one string\n",
    "# input per batch), and the dtype needs to be 'string'.\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorize_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sequential/text_vectorization/StaticRegexReplace_1:0\", shape=(None, 1), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "input_data = [[\"the movie was great\"], [\"hero did a great work\"]]\n",
    "pred = model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,  20,  14,  87,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [909, 113,   3,  87, 210,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=16\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  vectorize_layer,\n",
    "  tf.keras.layers.Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
    "  tf.keras.layers.GlobalAveragePooling1D(),\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Tensor(\"text_vectorization/StaticRegexReplace_3:0\", shape=(None, 1), dtype=string)\n",
      "Tensor(\"sequential_1/text_vectorization/StaticRegexReplace_1:0\", shape=(None, 1), dtype=string)\n",
      "Tensor(\"sequential_1/text_vectorization/StaticRegexReplace_1:0\", shape=(None, 1), dtype=string)\n",
      " 1/20 [>.............................] - ETA: 0s - loss: 0.6933 - accuracy: 0.5156WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.5009Tensor(\"sequential_1/text_vectorization/StaticRegexReplace_1:0\", shape=(None, 1), dtype=string)\n",
      "20/20 [==============================] - 21s 1s/step - loss: 0.6916 - accuracy: 0.5009 - val_loss: 0.6888 - val_accuracy: 0.4964\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 6s 287ms/step - loss: 0.6851 - accuracy: 0.5009 - val_loss: 0.6814 - val_accuracy: 0.4964\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 6s 288ms/step - loss: 0.6752 - accuracy: 0.5009 - val_loss: 0.6697 - val_accuracy: 0.4964\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 6s 296ms/step - loss: 0.6593 - accuracy: 0.5009 - val_loss: 0.6524 - val_accuracy: 0.4964\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 6s 285ms/step - loss: 0.6378 - accuracy: 0.5050 - val_loss: 0.6306 - val_accuracy: 0.5196\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 7s 371ms/step - loss: 0.6115 - accuracy: 0.5611 - val_loss: 0.6052 - val_accuracy: 0.5916\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 8s 408ms/step - loss: 0.5816 - accuracy: 0.6330 - val_loss: 0.5779 - val_accuracy: 0.6594\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 8s 387ms/step - loss: 0.5500 - accuracy: 0.6919 - val_loss: 0.5503 - val_accuracy: 0.7010\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 8s 410ms/step - loss: 0.5184 - accuracy: 0.7335 - val_loss: 0.5243 - val_accuracy: 0.7256\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 7s 328ms/step - loss: 0.4885 - accuracy: 0.7634 - val_loss: 0.5009 - val_accuracy: 0.7456\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 9s 441ms/step - loss: 0.4610 - accuracy: 0.7832 - val_loss: 0.4805 - val_accuracy: 0.7634\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 6s 297ms/step - loss: 0.4362 - accuracy: 0.7998 - val_loss: 0.4631 - val_accuracy: 0.7752\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 6s 285ms/step - loss: 0.4141 - accuracy: 0.8121 - val_loss: 0.4486 - val_accuracy: 0.7814\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 6s 285ms/step - loss: 0.3943 - accuracy: 0.8223 - val_loss: 0.4364 - val_accuracy: 0.7900\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 6s 290ms/step - loss: 0.3767 - accuracy: 0.8314 - val_loss: 0.4262 - val_accuracy: 0.7960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1446958bac0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds, \n",
    "    epochs=15,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 12872."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordEmbedding Replacing GlobalAveragePooling1D With Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=16\n",
    "\n",
    "model_faltten = tf.keras.models.Sequential([\n",
    "  vectorize_layer,\n",
    "  tf.keras.layers.Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_faltten.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Tensor(\"text_vectorization/StaticRegexReplace_5:0\", shape=(None, 1), dtype=string)\n",
      "Tensor(\"sequential_2/text_vectorization/StaticRegexReplace_1:0\", shape=(None, 1), dtype=string)\n",
      "Tensor(\"sequential_2/text_vectorization/StaticRegexReplace_1:0\", shape=(None, 1), dtype=string)\n",
      " 2/20 [==>...........................] - ETA: 19s - loss: 0.6933 - accuracy: 0.5093WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2698s vs `on_train_batch_end` time: 1.8743s). Check your callbacks.\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.5009Tensor(\"sequential_2/text_vectorization/StaticRegexReplace_1:0\", shape=(None, 1), dtype=string)\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 0.6924 - accuracy: 0.5009 - val_loss: 0.6902 - val_accuracy: 0.4964\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 6s 285ms/step - loss: 0.6754 - accuracy: 0.5012 - val_loss: 0.6692 - val_accuracy: 0.4992\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 6s 283ms/step - loss: 0.6114 - accuracy: 0.5709 - val_loss: 0.5855 - val_accuracy: 0.6316\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 6s 288ms/step - loss: 0.4814 - accuracy: 0.7598 - val_loss: 0.4841 - val_accuracy: 0.7624\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 6s 279ms/step - loss: 0.3611 - accuracy: 0.8443 - val_loss: 0.4333 - val_accuracy: 0.7936\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 6s 281ms/step - loss: 0.2760 - accuracy: 0.8894 - val_loss: 0.4144 - val_accuracy: 0.8008\n",
      "Epoch 7/15\n",
      "14/20 [====================>.........] - ETA: 1s - loss: 0.2182 - accuracy: 0.9238"
     ]
    }
   ],
   "source": [
    "model_faltten.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds, \n",
    "    epochs=15,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-7dbe98d19ef5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_faltten\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2349\u001b[0m     \"\"\"\n\u001b[0;32m   2350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2351\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2352\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2353\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model_faltten.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/new123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_layer('embedding').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0][9997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[\"isha speaks bad word\"],[\"neha  is silent girl and smart \"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_faltten.predict([[\"isha speaks bad word\"],[\"neha  is silent girl and smart \"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.get_layer('embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "for index, word in enumerate(vocab):\n",
    "    if  index == 0: continue # skip 0, it's padding.\n",
    "    vec = weights[index] \n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
