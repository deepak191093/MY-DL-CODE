{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics  import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import  OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)  and  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(inputData.shape,\" and \", type(inputData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)  and  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(y.shape,\" and \", type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData = inputData / 255 #to normilize the data\n",
    "nDigits   = 10 #output layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yOneHot = np.zeros((y.shape[0], nDigits)) #One Hot Encoding size = 70,000 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yOneHot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y.shape[0]):\n",
    "    yOneHot[i, int(y[i])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = yOneHot  # 70,000 * 10\n",
    "m = 60000 \n",
    "m_test = inputData.shape[0] - m # train data 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y[:m,:].reshape(m, nDigits), y[m:,:].reshape(m_test, nDigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputData_train, InputData_test = inputData[:m,:], inputData[m:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n",
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(InputData_train.shape)\n",
    "print(InputData_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "i = 7000\n",
    "plt.imshow(InputData_train[i,:].reshape(28,28), cmap = matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(y_train[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return z * (1 - z)\n",
    "    \n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return 0.5 * (np.sign(x) + 1)\n",
    "\n",
    "def softmax(y):\n",
    "    return np.exp(y) / np.sum(np.exp(y), axis=0)\n",
    "\n",
    "def CrossEntropyLoss(y, y_hat):\n",
    "    L_sum = np.sum(np.multiply(y, np.log(y_hat)))\n",
    "    m = y.shape[1]\n",
    "    L = (-1/m) * L_sum\n",
    "    return L\n",
    "\n",
    "def CE_Softmax_Derivative(output, ideal_output):\n",
    "    return output - ideal_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDim      = inputData.shape[1] # 784\n",
    "nHidden       = 64\n",
    "learning_rate = 1\n",
    "weight_deacy  = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = 0.01*np.random.randn(nHidden, inputDim) #  64 * 784\n",
    "b1 = np.zeros((nHidden, 1)) #  64\n",
    "W2 = 0.01*np.random.randn(nDigits, nHidden) # 10 * 64\n",
    "b2 = np.zeros((nDigits, 1)) #  10\n",
    "\n",
    "inputData = InputData_train\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 784)\n",
      "(10, 64)\n",
      "(64, 1)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(W1.shape)\n",
    "print(W2.shape)\n",
    "print(b1.shape)\n",
    "print(b2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 784) (60000, 784) (784, 60000)\n",
      "Z1 shape  (64, 60000)\n",
      "A1 shape  (64, 60000)\n",
      "Z2 shape  (10, 60000)\n",
      "A2 Shape  (10, 60000)\n",
      "2.3025926683067466 shape () size 1\n",
      "dZ2 shape  (60000, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 60000 is different from 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-4bb20d1d7607>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mdZ2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCE_Softmax_Derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dZ2 shape \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdZ2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 60,000 * 10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mdW2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdZ2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 60,000 * 10 , 60,000 * 64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dw2 shape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 60000 is different from 10)"
     ]
    }
   ],
   "source": [
    "nEpochs = 100\n",
    "costPlot = np.zeros(nEpochs)\n",
    "\n",
    "for i in range(nEpochs):\n",
    "    # feed forward start\n",
    "    print(W1.shape, inputData.shape, inputData.T.shape) # 64 * 784, 60,000 * 784, 784 * 60,000\n",
    "    Z1 = np.matmul(W1,inputData.T) + b1\n",
    "    print(\"Z1 shape \", Z1.shape)  # 64 * 60,000\n",
    "    A1 = relu(Z1)                 # 64 * 60,000\n",
    "    print(\"A1 shape \", A1.shape)  # 64 * 60,000 \n",
    "    Z2 = np.matmul(W2,A1) + b2    # 10 * 64 , 64 * 60,000\n",
    "    print(\"Z2 shape \", Z2.shape)  # 10 * 60,000\n",
    "    A2 = softmax(Z2)              # 10 * 60,000\n",
    "    print(\"A2 Shape \", A2.shape)  # 10 * 60,000\n",
    "    cost = CrossEntropyLoss(y.T, A2) \n",
    "    print(cost, \"shape\", cost.shape, \"size\", cost.size)\n",
    "    costPlot[i] = cost\n",
    "    # feed forward done\n",
    "    \n",
    "    # backpropagation start\n",
    "    dZ2 = CE_Softmax_Derivative(A2.T,y)\n",
    "    print(\"dZ2 shape \", dZ2.shape) # 60,000 * 10\n",
    "    dW2 = (1./m) * np.matmul(dZ2, A1.T) # 60,000 * 10 , 60,000 * 64\n",
    "    print(\"dw2 shape\", dW2.shape)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
