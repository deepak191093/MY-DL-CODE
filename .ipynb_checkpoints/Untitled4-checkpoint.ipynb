{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# importing libraries \n",
    "import speech_recognition as sr \n",
    "\n",
    "import os \n",
    "\n",
    "from pydub import AudioSegment \n",
    "from pydub.silence import split_on_silence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silence_based_conversion(path = \"alice-medium.wav\"):\n",
    "    print(path)\n",
    "  \n",
    "    # open the audio file stored in \n",
    "    # the local system as a wav file. \n",
    "    song = AudioSegment.from_wav(str(path)) \n",
    "  \n",
    "    # open a file where we will concatenate   \n",
    "    # and store the recognized text \n",
    "    fh = open(\"recognized.txt\", \"w+\") \n",
    "          \n",
    "    # split track where silence is 0.5 seconds  \n",
    "    # or more and get chunks \n",
    "    print(\"enter\")\n",
    "    chunks = split_on_silence(song, \n",
    "        # must be silent for at least 0.5 seconds \n",
    "        # or 500 ms. adjust this value based on user \n",
    "        # requirement. if the speaker stays silent for  \n",
    "        # longer, increase this value. else, decrease it. \n",
    "        min_silence_len = 100, \n",
    "  \n",
    "        # consider it silent if quieter than -16 dBFS \n",
    "        # adjust this per requirement \n",
    "        silence_thresh = -16\n",
    "    ) \n",
    "  \n",
    "    # create a directory to store the audio chunks. \n",
    "    try: \n",
    "        os.mkdir('audio_chunks') \n",
    "    except(FileExistsError): \n",
    "        pass\n",
    "  \n",
    "    # move into the directory to \n",
    "    # store the audio files. \n",
    "    os.chdir('audio_chunks') \n",
    "  \n",
    "    i = 0\n",
    "    # process each chunk \n",
    "    for chunk in chunks: \n",
    "              \n",
    "        # Create 0.5 seconds silence chunk \n",
    "        chunk_silent = AudioSegment.silent(duration = 10) \n",
    "  \n",
    "        # add 0.5 sec silence to beginning and  \n",
    "        # end of audio chunk. This is done so that \n",
    "        # it doesn't seem abruptly sliced. \n",
    "        audio_chunk = chunk_silent + chunk + chunk_silent \n",
    "  \n",
    "        # export audio chunk and save it in  \n",
    "        # the current directory. \n",
    "        print(\"saving chunk{0}.wav\".format(i)) \n",
    "        # specify the bitrate to be 192 k \n",
    "        audio_chunk.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\") \n",
    "  \n",
    "        # the name of the newly created chunk \n",
    "        filename = 'chunk'+str(i)+'.wav'\n",
    "  \n",
    "        print(\"Processing chunk \"+str(i)) \n",
    "  \n",
    "        # get the name of the newly created chunk \n",
    "        # in the AUDIO_FILE variable for later use. \n",
    "        file = filename \n",
    "  \n",
    "        # create a speech recognition object \n",
    "        r = sr.Recognizer() \n",
    "  \n",
    "        # recognize the chunk \n",
    "        with sr.AudioFile(file) as source: \n",
    "            # remove this if it is not working \n",
    "            # correctly. \n",
    "            r.adjust_for_ambient_noise(source) \n",
    "            audio_listened = r.listen(source) \n",
    "  \n",
    "        try: \n",
    "            # try converting it to text \n",
    "            rec = r.recognize_google(audio_listened) \n",
    "            # write the output to the file. \n",
    "            fh.write(rec+\". \") \n",
    "  \n",
    "        # catch any errors. \n",
    "        except sr.UnknownValueError: \n",
    "            print(\"Could not understand audio\") \n",
    "  \n",
    "        except sr.RequestError as e: \n",
    "            print(\"Could not request results. check your internet connection\") \n",
    "  \n",
    "        i += 1\n",
    "  \n",
    "    os.chdir('..') \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silence_based_conversion(\"b.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sr.AudioFile(\"KS.wav\") as source:\n",
    "    audio = r.listen(source)\n",
    "    try:\n",
    "        text  = r.recognize_google(audio)\n",
    "        print(text)\n",
    "    except:\n",
    "        print(\"sorry\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1. Start = 0 end = 5000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "recognize_wit() missing 1 required positional argument: 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-38fe78a812e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;31m# And catch expections.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mrec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_wit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_listened\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: recognize_wit() missing 1 required positional argument: 'key'"
     ]
    }
   ],
   "source": [
    "audio = AudioSegment.from_wav(\"b.wav\") \n",
    "  \n",
    "''' \n",
    "Step #1 - Slicing the audio file into smaller chunks. \n",
    "'''\n",
    "# Length of the audiofile in milliseconds \n",
    "n = len(audio) \n",
    "  \n",
    "# Variable to count the number of sliced chunks \n",
    "counter = 1\n",
    "  \n",
    "# Text file to write the recognized audio \n",
    "fh = open(\"recognized1.txt\", \"w+\") \n",
    "  \n",
    "# Interval length at which to slice the audio file. \n",
    "# If length is 22 seconds, and interval is 5 seconds, \n",
    "# The chunks created will be: \n",
    "# chunk1 : 0 - 5 seconds \n",
    "# chunk2 : 5 - 10 seconds \n",
    "# chunk3 : 10 - 15 seconds \n",
    "# chunk4 : 15 - 20 seconds \n",
    "# chunk5 : 20 - 22 seconds \n",
    "interval = 5 * 1000\n",
    "  \n",
    "# Length of audio to overlap.  \n",
    "# If length is 22 seconds, and interval is 5 seconds, \n",
    "# With overlap as 1.5 seconds, \n",
    "# The chunks created will be: \n",
    "# chunk1 : 0 - 5 seconds \n",
    "# chunk2 : 3.5 - 8.5 seconds \n",
    "# chunk3 : 7 - 12 seconds \n",
    "# chunk4 : 10.5 - 15.5 seconds \n",
    "# chunk5 : 14 - 19.5 seconds \n",
    "# chunk6 : 18 - 22 seconds \n",
    "overlap = 1.5 * 1000\n",
    "  \n",
    "# Initialize start and end seconds to 0 \n",
    "start = 0\n",
    "end = 0\n",
    "  \n",
    "# Flag to keep track of end of file. \n",
    "# When audio reaches its end, flag is set to 1 and we break \n",
    "flag = 0\n",
    "  \n",
    "# Iterate from 0 to end of the file, \n",
    "# with increment = interval \n",
    "for i in range(0, 2 * n, interval): \n",
    "      \n",
    "    # During first iteration, \n",
    "    # start is 0, end is the interval \n",
    "    if i == 0: \n",
    "        start = 0\n",
    "        end = interval \n",
    "  \n",
    "    # All other iterations, \n",
    "    # start is the previous end - overlap \n",
    "    # end becomes end + interval \n",
    "    else: \n",
    "        start = end - overlap \n",
    "        end = start + interval  \n",
    "  \n",
    "    # When end becomes greater than the file length, \n",
    "    # end is set to the file length \n",
    "    # flag is set to 1 to indicate break. \n",
    "    if end >= n: \n",
    "        end = n \n",
    "        flag = 1\n",
    "  \n",
    "    # Storing audio file from the defined start to end \n",
    "    chunk = audio[start:end] \n",
    "  \n",
    "    # Filename / Path to store the sliced audio \n",
    "    filename = 'chunk'+str(counter)+'.wav'\n",
    "  \n",
    "    # Store the sliced audio file to the defined path \n",
    "    chunk.export(filename, format =\"wav\") \n",
    "    # Print information about the current chunk \n",
    "    print(\"Processing chunk \"+str(counter)+\". Start = \"\n",
    "                        +str(start)+\" end = \"+str(end)) \n",
    "  \n",
    "    # Increment counter for the next chunk \n",
    "    counter = counter + 1\n",
    "      \n",
    "    # Slicing of the audio file is done. \n",
    "    # Skip the below steps if there is some other usage \n",
    "    # for the sliced audio files. \n",
    "    \n",
    "    AUDIO_FILE = filename \n",
    "  \n",
    "    # Initialize the recognizer \n",
    "    r = sr.Recognizer() \n",
    "  \n",
    "    # Traverse the audio file and listen to the audio \n",
    "    with sr.AudioFile(AUDIO_FILE) as source: \n",
    "        audio_listened = r.listen(source) \n",
    "  \n",
    "    # Try to recognize the listened audio \n",
    "    # And catch expections. \n",
    "    try:     \n",
    "        rec = r.recognize_google(audio_listened) \n",
    "        print(rec)\n",
    "          \n",
    "        # If recognized, write into the file. \n",
    "        fh.write(rec+\" \") \n",
    "      \n",
    "    # If google could not understand the audio \n",
    "    except sr.UnknownValueError: \n",
    "        print(\"Could not understand audio\") \n",
    "  \n",
    "    # If the results cannot be requested from Google. \n",
    "    # Probably an internet connection error. \n",
    "    except sr.RequestError as e: \n",
    "        print(\"Could not request results.\") \n",
    "  \n",
    "    # Check for flag. \n",
    "    # If flag is 1, end of the whole audio reached. \n",
    "    # Close the file and break. \n",
    "    if flag == 1: \n",
    "        fh.close() \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Wit speech API endpoint\n",
    "API_ENDPOINT = 'https://api.wit.ai/speech'\n",
    "\n",
    "# Wit.ai api access token\n",
    "wit_access_token = 'ZD6ZIDB43WCKO3QZBBP4P56BM33W7IZM'\n",
    "\n",
    "def read_audio(WAVE_FILENAME):\n",
    "    # function to read audio(wav) file\n",
    "    with open(WAVE_FILENAME, 'rb') as f:\n",
    "        audio = f.read()\n",
    "    return audio\n",
    "\n",
    "def RecognizeSpeech(AUDIO_FILENAME, num_seconds = 55):\n",
    "    audio = read_audio(AUDIO_FILENAME)\n",
    "\n",
    "    headers = {'authorization': 'Bearer ' + wit_access_token,\n",
    "               'Content-Type': 'audio/wav'}\n",
    "\n",
    "    # making an HTTP post request\n",
    "    resp = requests.post(API_ENDPOINT, headers = headers,\n",
    "                         data = audio)\n",
    "    \n",
    "    # converting response content to JSON format\n",
    "    data = json.loads(resp.content)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = AudioSegment.from_wav(\"b.wav\") \n",
    "  \n",
    "''' \n",
    "Step #1 - Slicing the audio file into smaller chunks. \n",
    "'''\n",
    "# Length of the audiofile in milliseconds \n",
    "n = len(audio) \n",
    "  \n",
    "# Variable to count the number of sliced chunks \n",
    "counter = 1\n",
    "  \n",
    "# Text file to write the recognized audio \n",
    "fh = open(\"recognized1.txt\", \"w+\") \n",
    "  \n",
    "# Interval length at which to slice the audio file. \n",
    "# If length is 22 seconds, and interval is 5 seconds, \n",
    "# The chunks created will be: \n",
    "# chunk1 : 0 - 5 seconds \n",
    "# chunk2 : 5 - 10 seconds \n",
    "# chunk3 : 10 - 15 seconds \n",
    "# chunk4 : 15 - 20 seconds \n",
    "# chunk5 : 20 - 22 seconds \n",
    "interval = 5 * 1000\n",
    "  \n",
    "# Length of audio to overlap.  \n",
    "# If length is 22 seconds, and interval is 5 seconds, \n",
    "# With overlap as 1.5 seconds, \n",
    "# The chunks created will be: \n",
    "# chunk1 : 0 - 5 seconds \n",
    "# chunk2 : 3.5 - 8.5 seconds \n",
    "# chunk3 : 7 - 12 seconds \n",
    "# chunk4 : 10.5 - 15.5 seconds \n",
    "# chunk5 : 14 - 19.5 seconds \n",
    "# chunk6 : 18 - 22 seconds \n",
    "overlap = 1.5 * 1000\n",
    "  \n",
    "# Initialize start and end seconds to 0 \n",
    "start = 0\n",
    "end = 0\n",
    "  \n",
    "# Flag to keep track of end of file. \n",
    "# When audio reaches its end, flag is set to 1 and we break \n",
    "flag = 0\n",
    "  \n",
    "# Iterate from 0 to end of the file, \n",
    "# with increment = interval \n",
    "for i in range(0, 2 * n, interval): \n",
    "      \n",
    "    # During first iteration, \n",
    "    # start is 0, end is the interval \n",
    "    if i == 0: \n",
    "        start = 0\n",
    "        end = interval \n",
    "  \n",
    "    # All other iterations, \n",
    "    # start is the previous end - overlap \n",
    "    # end becomes end + interval \n",
    "    else: \n",
    "        start = end - overlap \n",
    "        end = start + interval  \n",
    "  \n",
    "    # When end becomes greater than the file length, \n",
    "    # end is set to the file length \n",
    "    # flag is set to 1 to indicate break. \n",
    "    if end >= n: \n",
    "        end = n \n",
    "        flag = 1\n",
    "  \n",
    "    # Storing audio file from the defined start to end \n",
    "    chunk = audio[start:end] \n",
    "  \n",
    "    # Filename / Path to store the sliced audio \n",
    "    filename = 'chunk'+str(counter)+'.wav'\n",
    "  \n",
    "    # Store the sliced audio file to the defined path \n",
    "    chunk.export(filename, format =\"wav\") \n",
    "    # Print information about the current chunk \n",
    "    print(\"Processing chunk \"+str(counter)+\". Start = \"\n",
    "                        +str(start)+\" end = \"+str(end)) \n",
    "  \n",
    "    # Increment counter for the next chunk \n",
    "    counter = counter + 1\n",
    "      \n",
    "    # Slicing of the audio file is done. \n",
    "    # Skip the below steps if there is some other usage \n",
    "    # for the sliced audio files. \n",
    "    \n",
    "    AUDIO_FILE = filename \n",
    "  \n",
    "    API_ENDPOINT = 'https://api.wit.ai/speech'\n",
    "\n",
    "    # Wit.ai api access token\n",
    "    wit_access_token = 'ZD6ZIDB43WCKO3QZBBP4P56BM33W7IZM'\n",
    "    \n",
    "    text =  RecognizeSpeech('OSR_us_000_0010_8k.wav')\n",
    "    print(\"\\nYou said: {}\".format(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
